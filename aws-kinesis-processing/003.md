# Kinesis Building Blocks

## Streams in Kinesis

Sequence of registry logs that are appended on each write.

The logs lasts only 24 hours, after, they are automatically removed.

Basically is like Apache Kafka, there are many servers (shards) each one with a copy and a primare log.

The reads and writes are balanced in these different shards according to the scalability needs.

## How to write data to Kinesis

The record has a key and the data. Each partition (shard) is responsible to one key hash range. The record key is hashed and the result determines where (in which shard/partition) the data will be written.

This architecture agglutinates similar records for processing.

### How to select a Key

1. Random (tries to distribute igually the data)
2. Deduct from Data (meaningful keys - agglutinates similar records)

## How data is stored in Kinesis

### Kinesis Streams

Each Stream has _**N**_ shards. Each shard is composed by one **master** and _**N**_ replicas. The replicas guarantee availability. The distributed masters between many shards guarantee scalability.

## How data is read from Kinesis

The data is read from a persisted control file that points where is the data and from which shard the record will be processed. In case of failure, a replica assumes as master and a new replica is created in a health node. The persisted control file is kept updated in order to continue processing. 

## [Goback...](./index.md)